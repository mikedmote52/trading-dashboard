name: Market Intelligence Monitoring

on:
  schedule:
    # Run every 30 minutes during market hours (9:30 AM - 4:00 PM EST, Mon-Fri)
    - cron: '*/30 14-21 * * 1-5'  # UTC times (EST + 5)
    
  workflow_dispatch:  # Allow manual trigger
    inputs:
      sources:
        description: 'Data sources to monitor'
        required: false
        default: 'reddit,youtube,fda,sec'
        type: choice
        options:
          - reddit,youtube,fda,sec
          - reddit
          - youtube
          - fda
          - sec

jobs:
  monitor-reddit:
    runs-on: ubuntu-latest
    if: contains(github.event.inputs.sources || 'reddit,youtube,fda,sec', 'reddit')
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Install dependencies
        run: |
          npm install
          
      - name: Run Reddit monitoring
        env:
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
        run: |
          node -e "
          const RedditMonitor = require('./agents/reddit_monitor');
          const DiscoveryStorage = require('./utils/discovery_storage');
          
          async function scan() {
            const monitor = new RedditMonitor({
              clientId: process.env.REDDIT_CLIENT_ID,
              clientSecret: process.env.REDDIT_CLIENT_SECRET
            });
            
            const storage = new DiscoveryStorage('./data/market_intelligence');
            await storage.initialize();
            
            console.log('ğŸ” Starting Reddit scan...');
            const discoveries = await monitor.scanSubreddits();
            const formatted = monitor.formatDiscoveries(discoveries);
            
            console.log(\`Found \${formatted.length} discoveries\`);
            
            for (const signal of formatted) {
              await storage.saveSignal(signal);
              console.log(\`Saved: \${signal.symbol} - \${signal.confidence}\`);
            }
            
            return formatted;
          }
          
          scan().then(discoveries => {
            console.log('âœ… Reddit scan complete');
            process.exit(0);
          }).catch(err => {
            console.error('âŒ Reddit scan failed:', err);
            process.exit(1);
          });
          "
          
      - name: Upload discoveries
        uses: actions/upload-artifact@v3
        with:
          name: reddit-discoveries
          path: data/market_intelligence/discovery_signals.json
          retention-days: 7

  monitor-sec:
    runs-on: ubuntu-latest
    if: contains(github.event.inputs.sources || 'reddit,youtube,fda,sec', 'sec')
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install Python dependencies
        run: |
          pip install requests beautifulsoup4 pandas
          
      - name: Run SEC monitoring
        run: |
          python -c "
          import requests
          import json
          from datetime import datetime, timedelta
          
          # Fetch recent SEC filings
          def fetch_sec_filings():
              # Using SEC EDGAR API
              base_url = 'https://data.sec.gov/submissions/CIK{}.json'
              
              # This would normally fetch from SEC API
              # For now, create mock data
              filings = []
              
              # Check for significant forms
              significant_forms = ['8-K', '4', 'SC 13G', 'SC 13D']
              
              print(f'Fetched {len(filings)} SEC filings')
              return filings
          
          filings = fetch_sec_filings()
          
          # Save to file
          with open('data/sec_filings.json', 'w') as f:
              json.dump(filings, f)
          
          print('âœ… SEC monitoring complete')
          "
          
      - name: Upload SEC data
        uses: actions/upload-artifact@v3
        with:
          name: sec-filings
          path: data/sec_filings.json
          retention-days: 7

  process-confluences:
    runs-on: ubuntu-latest
    needs: [monitor-reddit, monitor-sec]
    if: always()
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Download artifacts
        uses: actions/download-artifact@v3
        
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Process confluences
        run: |
          node -e "
          const DiscoveryStorage = require('./utils/discovery_storage');
          
          async function processConfluences() {
            const storage = new DiscoveryStorage('./data/market_intelligence');
            await storage.initialize();
            
            // Check for signal confluences
            const history = await storage.getHistory();
            const confluences = [];
            
            for (const [symbol, data] of Object.entries(history)) {
              if (data.sources.length >= 2) {
                confluences.push({
                  symbol,
                  sources: data.sources,
                  signalCount: data.signalCount,
                  avgConfidence: data.avgConfidence,
                  timestamp: new Date().toISOString()
                });
              }
            }
            
            console.log(\`Found \${confluences.length} confluences\`);
            
            for (const confluence of confluences) {
              await storage.saveConfluence(confluence);
            }
            
            return confluences;
          }
          
          processConfluences().then(confluences => {
            console.log('âœ… Confluence processing complete');
            process.exit(0);
          }).catch(err => {
            console.error('âŒ Confluence processing failed:', err);
            process.exit(1);
          });
          "
          
  notify-discoveries:
    runs-on: ubuntu-latest
    needs: [process-confluences]
    if: success()
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Download confluences
        uses: actions/download-artifact@v3
        
      - name: Check for high-priority discoveries
        id: check
        run: |
          # Check if there are any high-confidence discoveries
          if [ -f "data/market_intelligence/confluences.json" ]; then
            HIGH_PRIORITY=$(jq '[.[] | select(.avgConfidence > 0.8)] | length' data/market_intelligence/confluences.json)
            echo "high_priority_count=$HIGH_PRIORITY" >> $GITHUB_OUTPUT
          else
            echo "high_priority_count=0" >> $GITHUB_OUTPUT
          fi
          
      - name: Create issue for high-priority discoveries
        if: steps.check.outputs.high_priority_count > 0
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const confluences = JSON.parse(fs.readFileSync('data/market_intelligence/confluences.json', 'utf8'));
            
            const highPriority = confluences.filter(c => c.avgConfidence > 0.8);
            
            const issueBody = `
            ## ğŸ¯ High-Priority Market Intelligence Discoveries
            
            ${highPriority.map(c => `
            ### ${c.symbol}
            - **Sources**: ${c.sources.join(', ')}
            - **Confidence**: ${(c.avgConfidence * 100).toFixed(0)}%
            - **Signal Count**: ${c.signalCount}
            `).join('\n')}
            
            ---
            *Generated by Market Intelligence Monitor*
            `;
            
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸ¯ Market Intelligence Alert - ${new Date().toLocaleDateString()}`,
              body: issueBody,
              labels: ['market-intelligence', 'high-priority']
            });

  cleanup-old-data:
    runs-on: ubuntu-latest
    needs: [notify-discoveries]
    if: always()
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Clean old discovery data
        run: |
          node -e "
          const DiscoveryStorage = require('./utils/discovery_storage');
          
          async function cleanup() {
            const storage = new DiscoveryStorage('./data/market_intelligence');
            await storage.initialize();
            await storage.cleanOldData();
            
            const stats = await storage.getStatistics();
            console.log('Storage statistics after cleanup:', stats);
          }
          
          cleanup().then(() => {
            console.log('âœ… Cleanup complete');
            process.exit(0);
          }).catch(err => {
            console.error('âŒ Cleanup failed:', err);
            process.exit(1);
          });
          "